{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all necessary library\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from pylab import rcParams\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#keras \n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential # a linear stack of neural network layers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten # the layers that are used in almost any neural network\n",
    "from keras.layers import Convolution2D, MaxPooling2D # 2D convolutional and pooling layer\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils # help us transform our data later\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define global parameter\n",
    "seed = 77\n",
    "np.random.seed(seed)\n",
    "\n",
    "batch_size = 16\n",
    "num_classes = 12\n",
    "num_epochs = 100\n",
    "\n",
    "# INPUT IMAGE DIMENSIONS\n",
    "img_row, img_col = 16, 16\n",
    "channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to load data\n",
    "def load_data():\n",
    "    pkl_file = open('../Data/Image.pkl', 'rb')\n",
    "    ImageF = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    \n",
    "\n",
    "    \n",
    "    pkl_file = open('../Data/targetdata.pkl', 'rb')\n",
    "    target = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    \n",
    "    \n",
    "    #unique households\n",
    "    pkl_file = open('../Data/housedata.pkl', 'rb')\n",
    "    households = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    \n",
    "    #house label\n",
    "    pkl_file = open('../Data/loc_label.pkl', 'rb')\n",
    "    loc_label = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    \n",
    "    #appliances label\n",
    "    pkl_file = open('../Data/Appliance_data.pkl', 'rb')\n",
    "    appliance = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    \n",
    "    return ImageF, target, households, loc_label, appliance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the cnn_model\n",
    "def cnn_model():\n",
    "    model = Sequential() # declare a sequential model\n",
    "    model.add(Convolution2D(32,    # number of filter layers\n",
    "                        3,    # y dimension of kernel (we're going for a 3x3 kernel)\n",
    "                        3,    # x dimension of kernel\n",
    "                        activation='relu',\n",
    "                        input_shape=(img_row, img_col, channel)))# Convolutional input layer, 32 feature maps with a size of 3×3 and a rectifier activation function\n",
    "    model.add(Convolution2D(32, 3, 3,activation='relu')) # Convolutional layer, 32 feature maps with a size of 3×3 and a rectifier activation function.\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) # Max Pool layer with size 2×2.\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))#Fully connected layer with 512 units and a rectifier activation function\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))#Fully connected output layer with 10 units and a softmax activation function.\n",
    "    \n",
    "    lrate = 0.01\n",
    "    decay = lrate/num_epochs\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'], verbose=0)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define Random forest model\n",
    "def rforest_model():\n",
    "    rForest = RandomForestClassifier(max_depth=10,n_estimators=20)\n",
    "    return rForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define classier model\n",
    "def classifiers(X_train,y_train,X_test,y_test):\n",
    "    '''\n",
    "    This is the classifier function. It takes training and validation data and excute the random forest and CNN model.\n",
    "    '''\n",
    "    acc = []\n",
    "    f_score = []\n",
    "    recall = []\n",
    "    prec = []\n",
    "    y_pred = []\n",
    "    model_name = [\"RandomForest\",\"Convolutional\"]\n",
    "    rForest = rforest_model()\n",
    "    cnnModel = cnn_model()\n",
    "    classifiers = [rForest,cnnModel]    \n",
    "    \n",
    "    for (i, model) in enumerate(classifiers):\n",
    "        \n",
    "        if model == cnnModel:\n",
    "            train_cnn= np.reshape(X_train, (X_train.shape[0],X_train.shape[1], X_train.shape[2],1))   # Reshape input \n",
    "            test_cnn= np.reshape(X_test, (X_test.shape[0], X_test.shape[1],X_test.shape[2], 1))\n",
    "            model.fit(train_cnn, y_train, batch_size=batch_size, nb_epoch=num_epochs, verbose=0, validation_data=(test_cnn, y_test))\n",
    "            pred_cnn=np.around(model.predict(test_cnn, batch_size=16, verbose=0))\n",
    "            acc.append(accuracy_score(y_test, pred_cnn))\n",
    "            f_score.append(f1_score(y_test, pred_cnn, average='macro'))\n",
    "            recall.append(recall_score(y_test, pred_cnn, average='macro'))\n",
    "            prec.append(precision_score(y_test, pred_cnn, average='macro'))\n",
    "            y_pred.append(pred_cnn) \n",
    "        \n",
    "        else:\n",
    "            train_forest=np.reshape(X_train,(len(X_train),img_row*img_col))\n",
    "            test_forest=np.reshape(X_test,(len(X_test),img_row*img_col))\n",
    "            model.fit(train_forest, y_train)\n",
    "            pred_forest=np.around(model.predict(test_forest))\n",
    "            acc.append(accuracy_score(y_test, pred_forest))\n",
    "            f_score.append(f1_score(y_test, pred_forest, average='macro'))\n",
    "            recall.append(recall_score(y_test, pred_forest, average='macro'))\n",
    "            prec.append(precision_score(y_test, pred_forest, average='macro'))\n",
    "            y_pred.append(pred_forest)\n",
    "            \n",
    "    \n",
    "\n",
    "    return (acc, f_score, recall, prec, y_pred, model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define evaluation function\n",
    "def evaluate_model():\n",
    "    data, target, house, label, appliance = load_data() # load data\n",
    "    target=np_utils.to_categorical(target,)\n",
    "    F = [data]\n",
    "    start = datetime.now()\n",
    "    num_house = len(house) # number of houses\n",
    "    num_model = 2 # number of model to evaluate\n",
    "    num_f = len(F) #number of feature\n",
    "    score_acc = []\n",
    "    score_prec = []\n",
    "    score_recall = []\n",
    "    f_score = []\n",
    "    acc = np.empty([num_f,num_model])\n",
    "    predictedY = [[np.empty([0],dtype='int')]*num_model]*num_f\n",
    "    trueY = np.empty([0],dtype='int')\n",
    "    name = []\n",
    "    \n",
    "    for i in range(num_house):   \n",
    "        print('%d/%d fold...\\t time consumed: %ds'%(i+1,num_house,(datetime.now()-start).seconds))\n",
    "        # split data into X_train,y_train,X_test,y_test based on households\n",
    "        test_index = np.where(label==i+1)[0]\n",
    "        train_index = np.where(label!=i+1)[0]\n",
    "       \n",
    "        \n",
    "        # loop over each feature\n",
    "        for (j,f) in enumerate(F):\n",
    "            X_train = data[train_index]\n",
    "            Y_train = target[train_index]\n",
    "            X_valid = data[test_index]\n",
    "            Y_valid = target[test_index]\n",
    "            \n",
    "            (acc, f1, recall, prec, y_pred, name) = classifiers(X_train, Y_train, X_valid, Y_valid)\n",
    "            \n",
    "            predictedY[j] = [np.hstack([predictedY[j][ii],np.argmax(y_pred[ii])]) for ii in range(num_model)]\n",
    "    \n",
    "        trueY = np.hstack([trueY,np.argmax(Y_valid)])\n",
    "        name.append(name)\n",
    "    \n",
    "    return (predictedY, trueY, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Format python plot with Latex\n",
    "SPINE_COLOR = 'gray'\n",
    "from math import sqrt\n",
    "\n",
    "def latexify(fig_width=None, fig_height=None, columns=1):\n",
    "    \"\"\"Set up matplotlib's RC params for LaTeX plotting.\n",
    "    Call this before plotting a figure.\n",
    "    Parameters\n",
    "    ----------\n",
    "    fig_width : float, optional, inches\n",
    "    fig_height : float,  optional, inches\n",
    "    columns : {1, 2}\n",
    "    \"\"\"\n",
    "\n",
    "    # code adapted from http://www.scipy.org/Cookbook/Matplotlib/LaTeX_Examples\n",
    "\n",
    "    # Width and max height in inches for IEEE journals taken from\n",
    "    # computer.org/cms/Computer.org/Journal%20templates/transactions_art_guide.pdf\n",
    "\n",
    "    assert(columns in [1,2])\n",
    "\n",
    "    if fig_width is None:\n",
    "        fig_width = 3.39 if columns==1 else 6.9 # width in inches\n",
    "\n",
    "    if fig_height is None:\n",
    "        golden_mean = (sqrt(5)-1.0)/2.0    # Aesthetic ratio\n",
    "        fig_height = fig_width*golden_mean # height in inches\n",
    "\n",
    "    MAX_HEIGHT_INCHES = 8.0\n",
    "    if fig_height > MAX_HEIGHT_INCHES:\n",
    "        print(\"WARNING: fig_height too large:\" + fig_height + \n",
    "              \"so will reduce to\" + MAX_HEIGHT_INCHES + \"inches.\")\n",
    "        fig_height = MAX_HEIGHT_INCHES\n",
    "\n",
    "    params = {'backend': 'ps',\n",
    "              'text.latex.preamble': ['\\\\usepackage{gensymb}'],\n",
    "              'axes.labelsize': 10, # fontsize for x and y labels (was 10)\n",
    "              'axes.titlesize': 14,\n",
    "              'text.fontsize': 12, # was 10\n",
    "              'legend.fontsize': 10, # was 10\n",
    "              'xtick.labelsize': 10,\n",
    "              'ytick.labelsize': 10,\n",
    "              'text.usetex': True,\n",
    "              'figure.figsize': [fig_width,fig_height],\n",
    "              'font.family': 'serif'\n",
    "            \n",
    "    }\n",
    "\n",
    "    matplotlib.rcParams.update(params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Format axes plot\n",
    "def format_axes(ax):\n",
    "\n",
    "    for spine in ['top', 'right']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "    for spine in ['left', 'bottom']:\n",
    "        ax.spines[spine].set_color(SPINE_COLOR)\n",
    "        ax.spines[spine].set_linewidth(0.5)\n",
    "\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    for axis in [ax.xaxis, ax.yaxis]:\n",
    "        axis.set_tick_params(direction='out', color=SPINE_COLOR)\n",
    "\n",
    "#    matplotlib.pyplot.tight_layout()\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bar plotting function\n",
    "def bar_plot(data_1, data_2,color, x_label,leg_label, title, plot_name):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "\n",
    "    ## the data\n",
    "    N = len(data_1)\n",
    "\n",
    "\n",
    "    ## necessary variables\n",
    "    ind = np.arange(N)                # the x locations for the groups\n",
    "    width = 0.35                      # the width of the bars\n",
    "\n",
    "    ## the bars\n",
    "    rects1 = ax.bar(ind, data_1, width, color=color[0])\n",
    "\n",
    "    rects2 = ax.bar(ind+width, data_2, width, color=color[1])\n",
    "\n",
    "    # axes and labels\n",
    "    ax.set_xlim(-width,len(ind)+width)\n",
    "    ax.set_ylim(0,1)\n",
    "    ax.set_ylabel('Scores\\n (Higher is better)')\n",
    "    ax.set_title(title)\n",
    "    xTickMarks = (x_label)\n",
    "    ax.set_xticks(ind+width)\n",
    "    xtickNames = ax.set_xticklabels(xTickMarks)\n",
    "    plt.setp(xtickNames, rotation=0)\n",
    "\n",
    "    ## add a legend\n",
    "    ax.legend( (rects1[0], rects2[0]), (leg_label[0], leg_label[1]) )\n",
    "    format_axes(ax)\n",
    "    \n",
    "    plt.savefig('../image/%s.pdf' %(plot_name), format='pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/55 fold...\t time consumed: 0s\n",
      "2/55 fold...\t time consumed: 80s\n",
      "3/55 fold...\t time consumed: 162s\n",
      "4/55 fold...\t time consumed: 245s\n",
      "5/55 fold...\t time consumed: 328s\n",
      "6/55 fold...\t time consumed: 416s\n",
      "7/55 fold...\t time consumed: 503s\n",
      "8/55 fold...\t time consumed: 596s\n",
      "9/55 fold...\t time consumed: 684s\n",
      "10/55 fold...\t time consumed: 776s\n",
      "11/55 fold...\t time consumed: 877s\n",
      "12/55 fold...\t time consumed: 974s\n",
      "13/55 fold...\t time consumed: 1074s\n",
      "14/55 fold...\t time consumed: 1177s\n",
      "15/55 fold...\t time consumed: 1285s\n",
      "16/55 fold...\t time consumed: 1383s\n",
      "17/55 fold...\t time consumed: 1474s\n",
      "18/55 fold...\t time consumed: 1571s\n",
      "19/55 fold...\t time consumed: 1663s\n",
      "20/55 fold...\t time consumed: 1760s\n",
      "21/55 fold...\t time consumed: 1852s\n",
      "22/55 fold...\t time consumed: 1943s\n",
      "23/55 fold...\t time consumed: 2037s\n",
      "24/55 fold...\t time consumed: 2130s\n",
      "25/55 fold...\t time consumed: 2225s\n",
      "26/55 fold...\t time consumed: 2321s\n",
      "27/55 fold...\t time consumed: 2415s\n",
      "28/55 fold...\t time consumed: 2511s\n",
      "29/55 fold...\t time consumed: 2618s\n",
      "30/55 fold...\t time consumed: 2729s\n",
      "31/55 fold...\t time consumed: 2851s\n",
      "32/55 fold...\t time consumed: 2960s\n",
      "33/55 fold...\t time consumed: 3064s\n",
      "34/55 fold...\t time consumed: 3158s\n",
      "35/55 fold...\t time consumed: 3253s\n",
      "36/55 fold...\t time consumed: 3350s\n",
      "37/55 fold...\t time consumed: 3447s\n",
      "38/55 fold...\t time consumed: 3544s\n",
      "39/55 fold...\t time consumed: 3640s\n",
      "40/55 fold...\t time consumed: 3735s\n",
      "41/55 fold...\t time consumed: 3834s\n",
      "42/55 fold...\t time consumed: 3925s\n",
      "43/55 fold...\t time consumed: 4021s\n",
      "44/55 fold...\t time consumed: 4117s\n",
      "45/55 fold...\t time consumed: 4211s\n",
      "46/55 fold...\t time consumed: 4315s\n",
      "47/55 fold...\t time consumed: 4415s\n",
      "48/55 fold...\t time consumed: 4519s\n",
      "49/55 fold...\t time consumed: 4622s\n",
      "50/55 fold...\t time consumed: 4726s\n",
      "51/55 fold...\t time consumed: 4826s\n",
      "52/55 fold...\t time consumed: 4933s\n",
      "53/55 fold...\t time consumed: 5039s\n",
      "54/55 fold...\t time consumed: 5141s\n",
      "55/55 fold...\t time consumed: 5250s\n"
     ]
    }
   ],
   "source": [
    "# Run the experiment\n",
    "y_p,y_t, name = evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Accuracy\n",
    "Acc = np.array([[accuracy_score(y_t, i) for i in j] for j in y_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "F1= np.array([[f1_score(y_t, i, average='macro') for i in j] for j in y_p])\n",
    "Recall = np.array([[recall_score(y_t, i, average='macro') for i in j] for j in y_p])\n",
    "Prec= np.array([[precision_score(y_t, i, average='macro') for i in j] for j in y_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAE9CAYAAAB0qQefAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFYIPABAVgg8AEJX/BSzCYdSUWe+fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faee0a07080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "latexify(columns=2, fig_height=5)\n",
    "data_1 = [F1[:,0], Recall[:,0], Prec[:,0]]\n",
    "data_2 = [F1[:,1], Recall[:,1], Prec[:,1]]\n",
    "color = ['blue','green']\n",
    "x_label = ['F_M','Recall', 'Precision']\n",
    "leg_label =[name[0], name[1]]\n",
    "bar_plot(data_1, data_2,color, x_label,leg_label, title=\"Evaluation Results\", plot_name=\"Results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
